---
title: "Whole-cube Bootstrap versus Group-specific Bootstrap"
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

When calculating biodiversity indicators from a cube, we often want confidence intervals (CIs) using bootstrapping. In **dubicube**, bootstrapping can be done in two ways:

* **Whole-cube bootstrapping**: resampling all rows in the cube, regardless of grouping.
* **Group-specific bootstrapping**: resampling rows only within a group of interest (e.g., a species, year, or habitat).

The choice between these two methods directly affects how confidence intervals should be interpreted:

* Other indicators **combine information across groups** (e.g., community richness, turnover, or multi-species metrics). These require whole-cube bootstrapping to preserve correlations.
* Some indicators are **calculated independently per group** (e.g., species-specific or year-specific metrics). For these, group-specific bootstrapping is usually more appropriate.

In this tutorial, we explain the differences, discuss the strengths and limitations of each method, and provide a worked example.

## Methods

```{r, echo=FALSE}
# Load packages
library(ggplot2)      # Data visualisation
library(dplyr)        # Data wrangling
library(tidyr)        # Data wrangling

# Data loading and processing
library(frictionless) # Load example datasets
library(b3gbi)        # Process occurrence cubes
library(dubicube)     # Analysis of data quality & indicator uncertainty
```

```{r, echo=FALSE}
# Read data package
b3data_package <- read_package(
  "https://zenodo.org/records/15211029/files/datapackage.json"
)

# Load bird cube data
bird_cube_belgium <- read_resource(b3data_package, "bird_cube_belgium_mgrs10")
head(bird_cube_belgium)

set.seed(123)

# Make dataset smaller
rows <- sample(nrow(bird_cube_belgium), 2000)
bird_cube_belgium <- bird_cube_belgium[rows, ]

# Process cube
processed_cube <- process_cube(
  bird_cube_belgium,
  first_year = 2015,
  last_year = 2018,
  cols_occurrences = "n"
)

# Function to calculate statistic of interest
# Mean number of observations per grid cell per year
mean_obs <- function(data) {
  obs <- x <- NULL

  data %>%
    dplyr::mutate(x = mean(obs), .by = "cellCode") %>%
    dplyr::summarise(diversity_val = mean(x), .by = "year") %>%
    as.data.frame()
}
```

### `dubicube`'s smart method

The smart option (`method = "smart"`) is the default behaviour of the `bootstrap_cube()` function. With this option, **dubicube** automatically selects the most appropriate bootstrap strategy based on:

1. **The scope of the indicator**
   Whether indicator values for each group are independent (group-specific) or depend on the full dataset (whole-cube). This is inferred by comparing indicator values computed on progressively smaller subsets of the data.

2. **The presence of a reference group**
   If a reference group is specified (`ref_group` not `NA`), bootstrapping via the **boot** package is disabled, because reference-based indicators require explicit resampling logic.

3. **The number of grouping variables**
   If more than one grouping variable is supplied (`length(grouping_var) > 1`), bootstrapping via the **boot** package is never used, even when `ref_group = NA`. In this case, `method = "smart"` always resolves to a non-boot method (`group_specific` or `whole_cube`), because multi-dimensional grouping is not compatible with the `boot` delegation used internally.

If no reference group is used *and* exactly one grouping variable is supplied, **dubicube** may delegate bootstrapping to the **boot** package for efficiency and robustness.


| Scope of indicator calculation | Reference group used? | Number of grouping variables | Method chosen by `method = "smart"` | Uses **boot** package? |
| ------------------------------ | --------------------- | ---------------------------- | ----------------------------------- | ---------------------- |
| Group-specific                 | No (`ref_group = NA`) | 1                            | `boot_group_specific`               | yes                    |
| Whole cube                     | No (`ref_group = NA`) | 1                            | `boot_whole_cube`                   | yes                    |
| Group-specific                 | Yes                   | any                          | `group_specific`                    | no                     |
| Whole cube                     | Yes                   | any                          | `whole_cube`                        | no                     |
| Group-specific                 | No (`ref_group = NA`) | > 1                          | `group_specific`                    | no                     |
| Whole cube                     | No (`ref_group = NA`) | > 1                          | `whole_cube`                        | no                     |

In practice, users rarely need to set the `method` argument explicitly. The default `method = "smart"` reliably selects an appropriate and valid bootstrap strategy. Explicitly setting `method` is mainly useful for advanced workflows, debugging, or methodological comparisons.

### Whole-cube bootstrap

**Definition:** Resample all rows in the cube, regardless of species, year, or other grouping.

**Advantages:**

* Preserves correlations between groups (e.g., species co-occurrence, temporal dependencies).
* Appropriate for indicators that depend on multiple groups together (community-level metrics, multi-species diversity).

**Disadvantages:**

* Rare groups may end up with zero rows in some bootstrap replicates, leading to wider or undefined CIs.
* Variance for small groups may be inflated.

**Use case examples:**

* Community richness per site or habitat.
* Multi-species indicators (e.g., average occupancy across species).
* Temporal turnover indicators that rely on multiple years.

**Implementation in `dubicube`**

* Use `method = "whole_cube"` in the `bootstrap_cube()` function.

```{r}
bootstrap_mean_whole <- bootstrap_cube(
  data_cube = processed_cube,
  fun = mean_obs,
  grouping_var = "year",
  samples = 1000,
  seed = 123,
  method = "whole_cube"
)
head(bootstrap_mean_whole)
```

### Group-specific bootstrap

**Definition:** Subset the cube by the group of interest (e.g., species or year), then resample rows only within that group.

**Advantages:**

* Guarantees each replicate has rows for the group → stable CIs.
* Reflects within-group variability only.

**Disadvantages:**

* Ignores correlations with other groups.
* Variance may be slightly underestimated if the group’s presence is correlated with other groups.

**Use case examples:**

* Species-specific occupancy or habitat preference metrics.
* Year-specific indicators (e.g., annual richness).
* Small or rare groups where zero-row replicates would be problematic.

**Implementation in `dubicube`**

* Use `method = "group_specific"` in the `bootstrap_cube()` function.

```{r}
bootstrap_mean_group <- bootstrap_cube(
  data_cube = processed_cube,
  fun = mean_obs,
  grouping_var = "year",
  samples = 1000,
  seed = 123,
  method = "group_specific"
)
head(bootstrap_mean_group)
```

### Bootstrapping with the **boot** package

For most use cases, **dubicube** delegates the resampling procedure to the well-established **boot** package (Canty et al., [2025](https://doi.org/10.32614/CRAN.package.boot)). This happens when:

* Automatically with `method = "smart"` (default), one grouping variable, and no reference group is specified (default)
* Manually with `method = "boot_whole_cube"` or `method = "boot_group_specific"`

In these cases, `bootstrap_cube()` returns the native objects produced by `boot::boot()`, rather than a summarised dataframe.

#### Whole-cube bootstrap with **boot**

When whole-cube bootstrapping is performed via **boot**, `bootstrap_cube()` returns a named list of `"boot"` objects, one per group.

```{r}
bootstrap_mean_boot_whole <- bootstrap_cube(
  data_cube = processed_cube,
  fun = mean_obs,
  grouping_var = "year",
  samples = 1000,
  seed = 123,
  method = "boot_whole_cube"
)
sapply(bootstrap_mean_boot_whole, class)
```

#### Group-specific bootstrap with **boot**

For group-specific bootstrapping via **boot**, `bootstrap_cube()` returns a named list of `"boot"` objects, one per group.

```{r}
bootstrap_mean_boot_group <- bootstrap_cube(
  data_cube = processed_cube,
  fun = mean_obs,
  grouping_var = "year",
  samples = 1000,
  seed = 123,
  method = "boot_group_specific"
)
sapply(bootstrap_mean_boot_group, class)
```

## Comparison between methods
### Comparing results

We perform bootstrapping and confidence interval calculation for the period **2015–2018**, following the same procedure as in previous tutorials. The results show that the bootstrap distributions and confidence intervals are very similar, regardless of whether the **boot** package is used.

```{r, echo=FALSE}
# Whole-cube to dataframe
bootstrap_mean_boot_whole_df <- boot_list_to_dataframe(
  boot_list = bootstrap_mean_boot_whole,
  grouping_var = "year"
)

# Group-specific to dataframe
bootstrap_mean_boot_group_df <- boot_list_to_dataframe(
  boot_list = bootstrap_mean_boot_group,
  grouping_var = "year"
)
```

```{r, echo=FALSE}
# Calculate confidence intervals
ci_mean_whole <- calculate_bootstrap_ci(
  bootstrap_samples_df = bootstrap_mean_whole,
  grouping_var = "year",
  type = c("perc", "bca", "norm", "basic"),
  conf = 0.95,
  data_cube = processed_cube,   # Required for BCa
  fun = mean_obs                # Required for BCa
)
ci_mean_group <- calculate_bootstrap_ci(
  bootstrap_samples_df = bootstrap_mean_group,
  grouping_var = "year",
  type = c("perc", "bca", "norm", "basic"),
  conf = 0.95,
  data_cube = processed_cube,   # Required for BCa
  fun = mean_obs                # Required for BCa
)
ci_mean_boot_whole <- calculate_bootstrap_ci(
  bootstrap_samples_df = bootstrap_mean_boot_whole,
  grouping_var = "year",
  type = c("perc", "bca", "norm", "basic"),
  conf = 0.95
)
ci_mean_boot_group <- calculate_bootstrap_ci(
  bootstrap_samples_df = bootstrap_mean_boot_group,
  grouping_var = "year",
  type = c("perc", "bca", "norm", "basic"),
  conf = 0.95
)
```

```{r, echo=FALSE}
# Combine datasets
bootstrap_results <- bind_rows(
  bootstrap_mean_whole %>%
    mutate(method = "whole_cube",
           boot = "no boot"),
  bootstrap_mean_group %>%
    mutate(method = "group_specific",
           boot = "no boot"),
  bootstrap_mean_boot_whole_df %>%
    mutate(year = as.numeric(year),
           method = "whole_cube",
           boot = "boot"),
  bootstrap_mean_boot_group_df %>%
    mutate(year = as.numeric(year),
           method = "group_specific",
           boot = "boot")
)

ci_results <- bind_rows(
  ci_mean_whole %>%
    mutate(method = "whole_cube",
           boot = "no boot"),
  ci_mean_group %>%
    mutate(method = "group_specific",
           boot = "no boot"),
  ci_mean_boot_whole %>%
    mutate(method = "whole_cube",
           boot = "boot",
           year = rep(sort(unique(processed_cube$data$year)), each = 4)),
  ci_mean_boot_group %>%
    mutate(method = "group_specific",
           boot = "boot",
           year = rep(sort(unique(processed_cube$data$year)), each = 4))
) %>%
  mutate(
    int_type = factor(
      int_type, levels = c("perc", "bca", "norm", "basic")
    )
  ) %>%
  select(year, int_type, ll, ul, method, boot)

# Get bias values
bias_mean_obs <- bootstrap_results %>%
  distinct(year, estimate = est_original, `bootstrap estimate` = est_boot,
           method, boot)

# Get estimate values
estimate_mean_obs <- bias_mean_obs %>%
  pivot_longer(cols = c("estimate", "bootstrap estimate"),
               names_to = "Legend", values_to = "value") %>%
  mutate(Legend = factor(Legend, levels = c("estimate", "bootstrap estimate"),
                         ordered = TRUE))
```

```{r, echo=FALSE, warning=FALSE}
#| fig.alt: >
#|   Comparison of results between bootstrap methods.
# Visualise
bootstrap_results %>%
  ggplot(aes(x = boot)) +
  # Distribution
  geom_violin(aes(y = rep_boot, group = boot),
              fill = alpha("cornflowerblue", 0.2)) +
  # Estimates and bias
  geom_point(data = estimate_mean_obs, aes(y = value, shape = Legend),
             colour = "firebrick", size = 2, alpha = 0.5) +
  # Intervals
  geom_errorbar(data = ci_results,
                aes(ymin = ll, ymax = ul, colour = int_type),
                position = position_dodge(0.8), linewidth = 0.8) +
  facet_grid(year ~ method, scales = "free") +
  # Settings
  labs(y = "Mean Number of Observations per Grid Cell",
       x = "", shape = "Legend:", colour = "Interval type:") +
  theme_minimal() +
  theme(legend.position = "bottom",
        legend.title = element_text(face = "bold"))
```

### Comparing speed

To illustrate the computational performance of the different bootstrapping strategies, we use the classic `iris` dataset. As a simple example indicator, we calculate the mean sepal length per species and quantify uncertainty using bootstrap-based confidence intervals.

```{r}
mean_sepal_length <- function(x) {
  out_df <- aggregate(Sepal.Length ~ Species, x, mean)
  names(out_df) <- c("Species", "diversity_val")
  out_df
}
```

```{r}
mean_sepal_length(iris)
```

We benchmark execution time using the **microbenchmark** package (Mersmann et al., [2024](https://doi.org/10.32614/CRAN.package.microbenchmark)).
Two computational steps are evaluated separately:

1. Bootstrap resampling using `bootstrap_cube()` (1,000 bootstrap samples)
2. Confidence interval calculation using `calculate_bootstrap_ci()` (all intervals (`"perc"`, `"bca"`, `"norm", `"basic"`))

For each step, we compare:

* Whole-cube vs group-specific resampling strategies, and
* Internal `dubicube` implementations vs delegation to the **boot** package.

The label "boot" indicates that `dubicube` relies on the **boot** package for resampling or interval calculation, whereas "no boot" denotes that the same task is performed using `dubicube`'s internal code paths.
Each method is executed 20 times and timings are reported in milliseconds.
All benchmarks are run with identical inputs and a fixed random seed to ensure comparability.

We observe that using the **boot** package results in faster performance for both bootstrapping and confidence interval calculation in the case of group-specific bootstrapping. For whole-cube bootstrapping, while interval calculation is faster with **boot**, the bootstrapping step itself is slower, which leads to a higher total computation time overall.

```{r, echo=FALSE, message=FALSE, results='hide'}
library(microbenchmark)

set.seed(123)

# Time bootstrapping
results_whole <- microbenchmark(
  {
    bootstrap_cube(
      data_cube = iris,
      fun = mean_sepal_length,
      grouping_var = "Species",
      samples = 1000,
      processed_cube = FALSE,
      method = "whole_cube"
    )
  },
  times = 20
)

results_group <- microbenchmark(
  {
    bootstrap_cube(
      data_cube = iris,
      fun = mean_sepal_length,
      grouping_var = "Species",
      samples = 1000,
      processed_cube = FALSE,
      method = "group_specific"
    )
  },
  times = 20
)

results_boot_whole <- microbenchmark(
  {
    bootstrap_cube(
      data_cube = iris,
      fun = mean_sepal_length,
      grouping_var = "Species",
      samples = 1000,
      processed_cube = FALSE,
      method = "boot_whole_cube"
    )
  },
  times = 20
)

results_boot_group <- microbenchmark(
  {
    bootstrap_cube(
      data_cube = iris,
      fun = mean_sepal_length,
      grouping_var = "Species",
      samples = 1000,
      processed_cube = FALSE,
      method = "boot_group_specific"
    )
  },
  times = 20
)

# Time confidence interval calculation
bootstrap_mean_whole <- bootstrap_cube(
  data_cube = iris,
  fun = mean_sepal_length,
  grouping_var = "Species",
  samples = 1000,
  processed_cube = FALSE,
  method = "whole_cube",
  seed = 123
)

bootstrap_mean_group <- bootstrap_cube(
  data_cube = iris,
  fun = mean_sepal_length,
  grouping_var = "Species",
  samples = 1000,
  processed_cube = FALSE,
  method = "group_specific",
  seed = 123
)

bootstrap_mean_boot_whole <- bootstrap_cube(
  data_cube = iris,
  fun = mean_sepal_length,
  grouping_var = "Species",
  samples = 1000,
  processed_cube = FALSE,
  method = "boot_whole_cube",
  seed = 123
)

bootstrap_mean_boot_group <- bootstrap_cube(
  data_cube = iris,
  fun = mean_sepal_length,
  grouping_var = "Species",
  samples = 1000,
  processed_cube = FALSE,
  method = "boot_group_specific",
  seed = 123
)

results_ci_whole <- microbenchmark(
  {
    calculate_bootstrap_ci(
      bootstrap_samples_df = bootstrap_mean_whole,
      grouping_var = "Species",
      type = c("perc", "bca", "norm", "basic"),
      conf = 0.95,
      data_cube = iris,         # Required for BCa
      fun = mean_sepal_length   # Required for BCa
    )
  },
  times = 20
)

results_ci_group <- microbenchmark(
  {
    calculate_bootstrap_ci(
      bootstrap_samples_df = bootstrap_mean_group,
      grouping_var = "Species",
      type = c("perc", "bca", "norm", "basic"),
      conf = 0.95,
      data_cube = iris,         # Required for BCa
      fun = mean_sepal_length   # Required for BCa
    )
  },
  times = 20
)

results_ci_boot_whole <- microbenchmark(
  {
    calculate_bootstrap_ci(
      bootstrap_samples_df = bootstrap_mean_boot_whole,
      grouping_var = "Species",
      type = c("perc", "bca", "norm", "basic"),
      conf = 0.95
    )
  },
  times = 20
)

results_ci_boot_group <- microbenchmark(
  {
    calculate_bootstrap_ci(
      bootstrap_samples_df = bootstrap_mean_boot_group,
      grouping_var = "Species",
      type = c("perc", "bca", "norm", "basic"),
      conf = 0.95
    )
  },
  times = 20
)
```


```{r, echo=FALSE}
# Create dataframes
bench_df <- bind_rows(
  as.data.frame(results_whole) %>%
    mutate(
      method = "whole-cube",
      boot   = "no boot"
    ),
  as.data.frame(results_group) %>%
    mutate(
      method = "group-specific",
      boot   = "no boot"
    ),
  as.data.frame(results_boot_whole) %>%
    mutate(
      method = "whole-cube",
      boot   = "boot"
    ),
  as.data.frame(results_boot_group) %>%
    mutate(
      method = "group-specific",
      boot   = "boot"
    )
) %>%
  mutate(
    time_ms = time / 1e6  # nanoseconds → milliseconds
  )

bench_ci_df <- bind_rows(
  as.data.frame(results_ci_whole) %>%
    mutate(
      method = "whole-cube",
      boot   = "no boot"
    ),
  as.data.frame(results_ci_group) %>%
    mutate(
      method = "group-specific",
      boot   = "no boot"
    ),
  as.data.frame(results_ci_boot_whole) %>%
    mutate(
      method = "whole-cube",
      boot   = "boot"
    ),
  as.data.frame(results_ci_boot_group) %>%
    mutate(
      method = "group-specific",
      boot   = "boot"
    )
) %>%
  mutate(
    time_ms = time / 1e6  # nanoseconds → milliseconds
  )
```

```{r, echo=TRUE, warning=FALSE}
#| fig.alt: >
#|   Comparison of execution time between methods.
# Combine bootstrapping and CI into one table
combined_df <- bind_rows(
  bench_df %>% mutate(id = row_number(), cat = "bootstrapping"),
  bench_ci_df %>% mutate(id = row_number(), cat = "ci_calculation")
)

# Compute total times per run
total_df <- combined_df %>%
  pivot_wider(
    id_cols = c("id", "method", "boot"),
    names_from = "cat",
    values_from = "time_ms"
  ) %>%
  mutate(total = bootstrapping + ci_calculation) %>%
  pivot_longer(
    cols = c("bootstrapping", "ci_calculation", "total"),
    names_to = "cat",
    values_to = "time_ms"
  ) %>%
  mutate(cat = factor(
    cat,
    levels = c("bootstrapping", "ci_calculation", "total"),
    labels = c("Bootstrapping", "CI calculation", "Total")
  ))

# Visualisation
total_df %>%
  mutate(
    boot = factor(boot, levels = c("no boot", "boot"))
  ) %>%
  ggplot(aes(x = boot, y = time_ms, fill = cat)) +
  geom_boxplot(position = "dodge", outlier.alpha = 0.6) +
  labs(
    x = "",
    y = "Execution time (ms)",
    fill = "Computation step"
  ) +
  facet_wrap(~method, scales = "free", nrow = 2) +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "bottom",
    strip.text = element_text(face = "bold", size = 14)
  )
```

