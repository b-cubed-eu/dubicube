---
title: "Calculating Bootstrap Confidence Intervals"
resource_files:
  - cache/bootstrap_results.Rds
  - cache/bootstrap_results_ref.Rds
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

When working with data cubes, it’s essential to understand the uncertainty surrounding derived statistics. This tutorial introduces the `calculate_bootstrap_ci()` function from **dubicube**,  which uses bootstrap replications to estimate the confidence intervals around statistics calculated from data cubes.

## Calculating bootstrap confidence intervals

In the [bootstrap tutorial](https://b-cubed-eu.github.io/dubicube/articles/bootstrap-method-cubes.html), we introduced bootstrapping as a way to assess the variability of statistics calculated from data cubes.
Bootstrapping involves repeatedly resampling the dataset and recalculating the statistic to create a distribution of possible outcomes (= bootstrap replicates).

This tutorial builds on that foundation by showing how to compute confidence intervals from those bootstrap replicates. Confidence intervals provide a useful summary of uncertainty by indicating a range within which the true value of the statistic is likely to be. We consider four different types of intervals (with confidence level $\alpha$). The choice of confidence interval types and their calculation is in line with the **boot** package in R (Canty & Ripley, [1999](https://CRAN.R-project.org/package=boot)), to ensure ease of implementation. They are based on the definitions provided by Davison & Hinkley ([1997, Chapter 5](https://doi.org/10.1017/CBO9780511802843)) (see also DiCiccio & Efron, [1996](https://doi.org/10.1214/ss/1032280214); Efron, [1987](https://doi.org/10.1080/01621459.1987.10478410)).

### 1. **Percentile**

Uses the percentiles of the bootstrap distribution.

$$
CI_{\text{perc}} = \left[ \hat{\theta}^*_{(\alpha/2)}, \hat{\theta}^*_{(1-\alpha/2)} \right]
$$

where $\hat{\theta}^*_{(\alpha/2)}$ and $\hat{\theta}^*_{(1-\alpha/2)}$ are the $\alpha/2$ and $1-\alpha/2$ percentiles of the bootstrap distribution, respectively.

---

### 2. **Bias-Corrected and Accelerated (BCa)**

Adjusts for bias and acceleration.

**Bias** refers to the systematic difference between the observed statistic from the original dataset and the center of the bootstrap distribution of the statistic. The bias correction term is calculated as:

$$
\hat{z}_0 = \Phi^{-1}\left(\frac{\#(\hat{\theta}^*_b < \hat{\theta})}{B}\right)
$$

where $\#$ is the counting operator and $\Phi^{-1}$ is the inverse cumulative density function of the standard normal distribution.

**Acceleration** quantifies how sensitive the variability of the statistic is to changes in the data. See further for how this is calculated:

- $a = 0$: The statistic's variability does not depend on the data (e.g., symmetric distribution)
- $a > 0$: Small changes in the data have a large effect on the statistic's variability (e.g., positive skew)
- $a < 0$: Small changes in the data have a smaller effect on the statistic's variability (e.g., negative skew)

The bias and acceleration estimates are then used to calculate adjusted percentiles:

$$
\alpha_1 = \Phi\left( \hat{z}_0 + \frac{\hat{z}_0 + z_{\alpha/2}}{1 - \hat{a}(\hat{z}_0 + z_{\alpha/2})} \right), \quad
\alpha_2 = \Phi\left( \hat{z}_0 + \frac{\hat{z}_0 + z_{1 - \alpha/2}}{1 - \hat{a}(\hat{z}_0 + z_{1 - \alpha/2})} \right)
$$

So, we get:

$$
CI_{\text{bca}} = \left[ \hat{\theta}^*_{(\alpha_1)}, \hat{\theta}^*_{(\alpha_2)} \right]
$$

---

### 3. **Normal**

Assumes the bootstrap distribution of the statistic is approximately normal:

$$
CI_{\text{norm}} = \left[\hat{\theta} - \text{Bias}_{\text{boot}} - \text{SE}_{\text{boot}} \cdot z_{1-\alpha/2},
\hat{\theta} - \text{Bias}_{\text{boot}} + \text{SE}_{\text{boot}} \cdot z_{1-\alpha/2} \right]
$$

where $z_{1-\alpha/2}$ is the $1-\alpha/2$ quantile of the standard normal distribution.

---

### 4. **Basic**

Centers the interval using percentiles:

$$
CI_{\text{basic}} = \left[ 2\hat{\theta} - \hat{\theta}^*_{(1-\alpha/2)},
2\hat{\theta} - \hat{\theta}^*_{(\alpha/2)} \right]
$$

where $\hat{\theta}^*_{(\alpha/2)}$ and $\hat{\theta}^*_{(1-\alpha/2)}$ are the $\alpha/2$ and $1-\alpha/2$ percentiles of the bootstrap distribution, respectively.

## Calculating acceleration

The acceleration is calculated as follows:

$$
\hat{a} = \frac{1}{6} \frac{\sum_{i = 1}^{n}(I_i^3)}{\left( \sum_{i = 1}^{n}(I_i^2) \right)^{3/2}}
$$

where $I_i$ denotes the influence of data point $x_i$ on the estimation of $\theta$.
$I_i$ can be estimated using jackknifing.
Examples are (1) the negative jackknife: $I_i = (n-1)(\hat{\theta} - \hat{\theta}_{-i})$, and (2) the positive jackknife $I_i = (n+1)(\hat{\theta}_{-i} - \hat{\theta})$ (Frangos & Schucany, [1990](https://doi.org/10.1016/0167-9473(90)90109-U)).
Here, $\hat{\theta}_{-i}$ is the estimated value leaving out the $i$’th data point $x_i$.
The **boot** package (Canty & Ripley, [1999](https://CRAN.R-project.org/package=boot)) also offers infinitesimal jackknife and regression estimation.
Implementation of these jackknife algorithms can be explored in the future.

In case of the BCa interval, `calculate_bootstrap_ci()` uses the function `calculate_acceleration()` to calculate acceleration.
The latter can also be used on its own to calculate acceleration values to quantify the sensitivity
of a statistic’s variability to changes in the dataset.
For jackknifing, the it uses the `perform_jackknifing()` function which is not exported by **dubicube**.

## Getting started with dubicube

Our method can be used on any dataframe from which a statistic is calculated and a grouping variable is present.
For this tutorial, we focus on occurrence cubes.
Therefore, we will use the **b3gbi** package for processing the raw data before we go over to bootstrapping.

```{r, message=FALSE, warning=FALSE}
# Load packages
library(dubicube)

# Data loading and processing
library(frictionless) # Load example datasets
library(b3gbi)        # Process occurrence cubes

# General
library(ggplot2)      # Data visualisation
library(dplyr)        # Data wrangling
```

### Loading and processing the data

We load the bird cube data from the **b3data** data package using **frictionless** (see also [here](https://github.com/b-cubed-eu/b3data-scripts)).
It is an occurrence cube for birds in Belgium between 2000 en 2024 using the MGRS grid at 10 km scale.

```{r}
# Read data package
b3data_package <- read_package(
  "https://zenodo.org/records/15211029/files/datapackage.json"
)

# Load bird cube data
bird_cube_belgium <- read_resource(b3data_package, "bird_cube_belgium_mgrs10")
head(bird_cube_belgium)
```

We process the cube with **b3gbi**.
We select the data from 2011 - 2020.

```{r}
processed_cube <- process_cube(
  bird_cube_belgium,
  first_year = 2011,
  last_year = 2020,
  cols_occurrences = "n"
)
processed_cube
```

### Analysis of the data

Let's say we are interested in the mean number of observations per grid cell per year.
We create a function to calculate this.

```{r}
# Function to calculate statistic of interest
# Mean observations per grid cell per year
mean_obs <- function(data) {
  obs <- x <- NULL

  data %>%
    dplyr::mutate(x = mean(obs), .by = "cellCode") %>%
    dplyr::summarise(diversity_val = mean(x), .by = "year") %>%
    as.data.frame()
}
```

We get the following results:

```{r}
mean_obs(processed_cube$data)
```

On their own, these values don’t reveal how much uncertainty surrounds them. To better understand their variability, we use bootstrapping to estimate the distribution of the yearly means. From this, we can calculate bootstrap confidence intervals.

### Bootstrapping

We use the `bootstrap_cube()` function to perform bootstrapping (see also the [bootstrap tutorial](https://b-cubed-eu.github.io/dubicube/articles/bootstrap-method-cubes.html)).

```{r, echo=FALSE, message=FALSE}
# Create cache directory
cache_path <- here::here("vignettes", "articles", "cache")
dir.create(cache_path, showWarnings = FALSE, recursive = TRUE)

bootstrap_results_path <- file.path(cache_path, "bootstrap_results.Rds")
if (file.exists(bootstrap_results_path)) {
  bootstrap_results <- readRDS(bootstrap_results_path)
} else {
  bootstrap_results <- bootstrap_cube(
    data_cube = processed_cube$data,
    fun = mean_obs,
    grouping_var = "year",
    samples = 1000,
    seed = 123
  )
  saveRDS(bootstrap_results, bootstrap_results_path)
}
```

```r
bootstrap_results <- bootstrap_cube(
  data_cube = processed_cube$data,
  fun = mean_obs,
  grouping_var = "year",
  samples = 1000,
  seed = 123
)
```

```{r}
head(bootstrap_results)
```

### Interval calculation

Now we can use the `calculate_bootstrap_ci()` function to calculate confidence limits. It relies on the following arguments:

- **`bootstrap_samples_df`**:
  A dataframe containing the bootstrap replicates, where each row represents a bootstrap sample. As returned by `bootstrap_cube()`.

- **`grouping_var`**:
  The column(s) used for grouping the output of `fun()`. For example, if `fun()` returns one value per year, use `grouping_var = "year"`.

- **`type`**:
  A character vector specifying the type(s) of confidence intervals to compute. Options include:
    - `"perc"`: Percentile interval
    - `"bca"`: Bias-corrected and accelerated interval
    - `"norm"`: Normal interval
    - `"basic"`: Basic interval
    - `"all"`: Compute all available interval types (default)

- **`conf`**:
  The confidence level of the intervals. Default is `0.95` (95 % confidence level).

- **`aggregate`**:
  Logical. If `TRUE` (default), the function returns confidence limits per group. If `FALSE`, the confidence limits are added to the original bootstrap dataframe `bootstrap_samples_df`.

- **`data_cube`**:
  Only used when `type = "bca"`. The input data, either as a processed data cube (from `b3gbi::process_cube()`), or simply the dataframe inside it (i.e. `processed_cube$data`). For faster computation, passing just the dataframe is recommended.

- **`fun`**:
  Only used when `type = "bca"`. A user-defined function that computes the statistic(s) of interest from `data_cube`. This function should return a dataframe that includes a column named `diversity_val`, containing the statistic to evaluate.

- **progress**:
  Logical flag to show a progress bar. Set to `TRUE` to enable progress reporting; default is `FALSE`.

> **Note:** The BCa interval (`type = "bca"`) is currently not calculated in this tutorial due to its high computational cost. We are actively exploring options to improve its performance and enable faster computation in future releases.

```{r, echo=FALSE, message=FALSE}
ci_mean_obs_path <- file.path(cache_path, "ci_mean_obs.Rds")
if (file.exists(ci_mean_obs_path)) {
  ci_mean_obs <- readRDS(ci_mean_obs_path)
} else {
  ci_mean_obs <- calculate_bootstrap_ci(
    bootstrap_samples_df = bootstrap_results,
    grouping_var = "year",
    type = c("perc", "norm", "basic"),
    conf = 0.95,
    data_cube = processed_cube$data,
    fun = mean_obs
  )
  saveRDS(ci_mean_obs, ci_mean_obs_path)
}
```

```r
ci_mean_obs <- calculate_bootstrap_ci(
  bootstrap_samples_df = bootstrap_results,
  grouping_var = "year",
  type = c("perc", "norm", "basic"),
  conf = 0.95,
  data_cube = processed_cube$data,
  fun = mean_obs
)
```
  
```{r}
head(ci_mean_obs)
```

We visualise the distribution of the bootstrap replicates and the confidence intervals.
Since we have nice symmetrical distribution, all confidence intervals are very similar.

```{r}
# Make interval type factor
ci_mean_obs <- ci_mean_obs %>%
  mutate(
    int_type = factor(
      int_type, levels = c("norm", "basic", "perc", "bca")
    )
  )
```

```{r}
# Get bias vales
bias_mean_obs <- bootstrap_results %>%
  distinct(year, estimate = est_original, `bootstrap estimate` = est_boot)

# Get estimate values
estimate_mean_obs <- bias_mean_obs %>%
  tidyr::pivot_longer(cols = c("estimate", "bootstrap estimate"),
                      names_to = "Legend", values_to = "value") %>%
  mutate(Legend = factor(Legend, levels = c("estimate", "bootstrap estimate"),
                         ordered = TRUE))
# Visualise
bootstrap_results %>%
  ggplot(aes(x = year)) +
  # Distribution
  geom_violin(aes(y = rep_boot, group = year),
              fill = alpha("cornflowerblue", 0.2)) +
  # Estimates and bias
  geom_point(data = estimate_mean_obs, aes(y = value, shape = Legend),
             colour = "firebrick", size = 2, alpha = 0.5) +
  # Intervals
  geom_errorbar(data = ci_mean_obs,
                aes(ymin = ll, ymax = ul, colour = int_type),
                position = position_dodge(0.8), linewidth = 0.8) +
  # Settings
  labs(y = "Mean Number of Observations\nper Grid Cell",
       x = "", shape = "Legend:", colour = "Interval type:") +
  scale_x_continuous(breaks = sort(unique(bootstrap_results$year))) +
  theme_minimal() +
  theme(legend.position = "bottom",
        legend.title = element_text(face = "bold"))
```

## Advanced usage of `calculate_bootstrap_ci()`
### Comparison with a reference group

...

If a reference group is used, jackknifing is implemented in a different way.
Consider $\hat{\theta} = \hat{\theta}_1 - \hat{\theta}_2$ where $\hat{\theta}_1$ is the estimate for the indicator value of a non-reference period (sample size $n_1$) and $\hat{\theta}_2$ is the estimate for the indicator value of a reference period (sample size $n_2$).
The acceleration is now calculated as follows:

$$
\hat{a} = \frac{1}{6} \frac{\sum_{i = 1}^{n_1 + n_2}(I_i^3)}{\left( \sum_{i = 1}^{n_1 + n_2}(I_i^2) \right)^{3/2}}
$$

$I_i$ can be calculated using the negative or positive jackknife. Such that

$\hat{\theta}_{-i} = \hat{\theta}_{1,-i} - \hat{\theta}_2 \text{ for } i = 1, \ldots, n_1$, and

$\hat{\theta}_{-i} = \hat{\theta}_{1} - \hat{\theta}_{2,-i} \text{ for } i = n_1 + 1, \ldots, n_1 + n_2$

### Transformations and bias correction options

...
